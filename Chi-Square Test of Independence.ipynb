{
 "metadata": {
  "name": "",
  "signature": "sha256:37f197f7ef1a532caeb79689ada39dd1650bb878b3a7dddbf5321da2e5eef580"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chi-Square Test of Independence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`\n",
      "Author: Samuel M.H. <samuel.mh@gmail.com>\n",
      "Date: 24-01-2016\n",
      "`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Instructions## \n",
      "\n",
      "Run a Chi-Square Test of Independence.\n",
      "\n",
      "You will need to analyze and interpret post hoc paired comparisons in instances where your original statistical test was significant, and you were examining more than two groups (i.e. more than two levels of a categorical, explanatory variable). \n",
      "\n",
      "Note: although it is possible to run large Chi-Square tables (e.g. 5 x 5, 4 x 6, etc.), the test is really only interpretable when your response variable has only 2 levels (see Graphing decisions flow chart in Bivariate Graphing chapter)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Dataset ##\n",
      "* National Epidemiological Survey on Alcohol and Related Conditions (NESARC)\n",
      "* [CSV file](https://d396qusza40orc.cloudfront.net/phoenixassets/data-management-visualization/nesarc_pds.csv)\n",
      "* [File description](https://d396qusza40orc.cloudfront.net/phoenixassets/data-management-visualization/NESARC%20Wave%201%20Code%20Book%20w%20toc.pdf)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import pandas\n",
      "import numpy\n",
      "import scipy.stats\n",
      "import seaborn\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "data = pandas.read_csv('../datasets/NESARC/nesarc_pds.csv', low_memory=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Test of independence - $\\chi^2$##\n",
      "I am testing if the race (explanatory variable - signal ETHRACE2A) is related to have had problems with a neighbor, friend or relative in the last twelve months (response variable - signal S1Q239)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1 = pandas.DataFrame()\n",
      "problems = {1:'Y',2:'N'}\n",
      "df1['PROBLEMS'] = data['S1Q239'].replace(9, numpy.nan).map(problems)\n",
      "races = {1:'white',2:'black',3:'indian(US)',4:'asian',5:'latino'}\n",
      "df1['RACE'] = data['ETHRACE2A'].map(races)\n",
      "df1 = df1.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Contingency table, observations\n",
      "ct1 = pandas.crosstab(df1['PROBLEMS'],df1['RACE'])\n",
      "print ct1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RACE      asian  black  indian(US)  latino  white\n",
        "PROBLEMS                                         \n",
        "N          1277   7711         618    7846  22855\n",
        "Y            46    447          79     399   1449\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Percentages\n",
      "colsum = ct1.sum(axis=0)\n",
      "colpct = ct1/colsum\n",
      "print (colpct)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RACE         asian     black  indian(US)    latino    white\n",
        "PROBLEMS                                                   \n",
        "N         0.965231  0.945207    0.886657  0.951607  0.94038\n",
        "Y         0.034769  0.054793    0.113343  0.048393  0.05962\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*NOTE:* summed by column (explanatory variable) because I want to know how the problems rate vary on different groups."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# chi-square test\n",
      "cs1 = scipy.stats.chi2_contingency(ct1)\n",
      "print(\"X\u00b2 Value = {0}\".format(cs1[0]))\n",
      "print(\"p-value = {0}\".format(cs1[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X\u00b2 Value = 68.8411951763\n",
        "p-value = 3.98639461627e-14\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The $\\chi^2$ test of indepence gives a p-value lesser than 0.05, so the race and having problems are significantly associated.\n",
      "\n",
      "**Not all problem rates are equal across race categories.**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Post hoc test - Bonferroni Adjustment##\n",
      "\n",
      "* Number of categories: 5\n",
      "* Number of comparisons: $\\binom{5}{2} = 10$\n",
      "* Adjusted p-value: $\\frac{p-value}{number of comparisons} = \\frac{0.05}{10} = 0.005$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import combinations\n",
      "comparison_pairs = list(combinations(races.values(),2))\n",
      "ap_val = 0.05/len(comparison_pairs) #Adjusted p-value\n",
      "\n",
      "for (v1,v2) in comparison_pairs:\n",
      "    df2 = df1[(df1['RACE']==v1) | (df1['RACE']==v2)]\n",
      "    ct2 = pandas.crosstab(df2['PROBLEMS'],df2['RACE'])\n",
      "    cs2 = scipy.stats.chi2_contingency(ct2)\n",
      "    print(\"PAIR: {0}-{1}\".format(v1,v2,cs2[1],cs2[1]<0.05))\n",
      "    print(\"\\t p-value: {0}\".format(cs2[1]))\n",
      "    print(\"\\t Reject: {0}\".format(cs2[1]<ap_val))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PAIR: white-black\n",
        "\t p-value: 0.113799397668\n",
        "\t Reject: False\n",
        "PAIR: white-indian(US)\n",
        "\t p-value: 8.5313833522e-09\n",
        "\t Reject: True\n",
        "PAIR: white-asian\n",
        "\t p-value: 0.000219535658413\n",
        "\t Reject: True\n",
        "PAIR: white-latino"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t p-value: 0.000157439063204\n",
        "\t Reject: True\n",
        "PAIR: black-indian(US)\n",
        "\t p-value: 5.88958554652e-10\n",
        "\t Reject: True\n",
        "PAIR: black-asian\n",
        "\t p-value: 0.00291931342441\n",
        "\t Reject: True\n",
        "PAIR: black-latino\n",
        "\t p-value: 0.0691126102707\n",
        "\t Reject: False\n",
        "PAIR: indian(US)-asian"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\t p-value: 6.39541615117e-12\n",
        "\t Reject: True\n",
        "PAIR: indian(US)-latino\n",
        "\t p-value: 4.7511807716e-13\n",
        "\t Reject: True\n",
        "PAIR: asian-latino\n",
        "\t p-value: 0.0345111728606\n",
        "\t Reject: False\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following matrix shows with an \"`x`\" when the null hypothesis $H_0$ can be rejected and the variables are not independent.\n",
      "\n",
      "| |W|B|I|A|L|\n",
      "|-|-|-|-|-|-|\n",
      "|W| | | | | |\n",
      "|B|-| | | | |\n",
      "|I|x|x| | | |\n",
      "|A|x|x|x| | |\n",
      "|L|x|-|x|-| |\n",
      "\n",
      "*The letter stands for the first letter of the race, i.e. W-> white, A->asian*"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}